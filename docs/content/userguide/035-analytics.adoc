<<<

:linkattrs:

== Analytics

[[analytics-overview]]
=== Overview

Analytics embody algorithms tailored to geospatial data.  Most analytics leverage Hadoop MapReduce for bulk computation. Results of analytic jobs consist of vector or raster data stored in GeoWave.

[NOTE]
====
When running analytics, GeoWave does not remove duplicate features that reference lines and/or polygons spanning multiple index regions. If working with duplication in time ranges, please take a look at the GeoWave {core-mapreduce}/mapreduce/dedupe/GeoWaveDedupeJobRunner.java[`GeoWaveDedupeJobRunner`, window="_blank"].

It is important to note that the default spatial indexing strategy does not produce duplicates. The only time there would be a duplication issue is if you are indexing a time range and the time range spans multiple periods based on your temporal binning strategy. The default temporal periodicity is "YEAR," meaning that a row will be duplicated under the default spatial-temporal indexing if the data has a temporal range that crosses the threshold between December 31 and January 1 of the following year.
====

GeoWave provides the following algorithms out of the box.

[width="100%",cols="2,10",options="header"]
|=========================================================
|Name |Description
|KMeans++| A K-means implementation to find K centroids over the population of data. A set of preliminary sampling iterations find an optimal value of K and the initial set of K centroids. The algorithm produces K centroids and their associated polygons.  Each polygon represents the concave hull containing all features associated with a centroid. The algorithm supports drilling down multiple levels. At each level, the set centroids are determined from the set of features associated the same centroid from the previous level.
|KMeans Jump| Uses KMeans++ over a range of K, choosing an optimal K using an information theoretic based measurement.
|KMeans Parallel| A K-means implementation that is performed in parallel.
|KMeans Spark| A K-means implementation that is performed with Spark ML.
|KDE| A Kernel Density Estimation implementation that produces a density raster from input vector data.
|KDE Spark| Executes the KDE implementation using Apache Spark.
|DBScan| The Density Based Scanner algorithm produces a set of convex polygons for each region meeting density criteria. Density of region is measured by a minimum cardinality of enclosed features within a specified distance from each other.
|Nearest Neighbors| An infrastructure component that produces all the neighbors of a feature within a specific distance.
|=========================================================

For more information about running each of these analytics, see the link:commands.html#analytic-commands[GeoWave CLI Documentation].

